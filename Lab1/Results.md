# Исследование компиляторов LLVM и GCC для risc-v

## Ход исследования

Для исследования измеряли скорость сортировки массива алгоритмом O(n^2) на различных длинах массива случайных чисел при разных оптимизациях компилятора.

В результате получили графики времени выполнения программы:

![графики](./all_grath.png)

Как видно из графика оптимизации значительно уменьшают время выполнения программы, так что уберем графики для О0.

![графики](./O0+.png)

Поведения оптимизаций llvm ожидаемо, чем выше уровень тем быстрее выполняется программа, но 3 уровень уже не даёт ускорения, тогда как с gcc все не так однозначно. Наибольшего ускорения получается достичь при O1 оптимизации, тогда как для следующих оптимизация результат значительно ухудшается.

К тому же видно что время выполнения кода после gcc не стабильно, бывают "скачки". Коэффициент детерминации R^2 для двух лучших результатов gcc и llvm соответственно: 0.9803 и 0.9997.

![O2 llvm и O1 gcc](best_only.png)

Но несмотря на выбросы, llvm медленнее на 6.7%.

## Типа Вывод

Gcc имеет смысл использовать только с O1, а llvm с O2, т.к. они выда.т лучшие результаты, при этом результат gсс сильно не стабилен пусть и на 7% лучше чем llvm.

# Часть Вторая Исследуем ассемблер

## Подготовка

Я решил дописать пару команд в make, чтобы сразу компилировать до ассемблера в докере разными компиляторами (да я помню про переменные окружения, но в этом проекте я уже решил добить все по-старинке).

## GCC

### Первый взгляд на ассемблер

Сразу бросается в глаза количество строчек, у O0 242, у O1 178, а у О2 и О3 по 179. Сравнение максимально тупое, но корреляция с результатами прошлого теста есть.

### Адекватный взгляд на ассемблер

Т.к. на учитываемое время выполнения программы влияет только функция сортировки, то будем рассматривать пристально только ее. 

Также я считаю что рассматривать ассемблер без оптимизаций особо не целесообразно в связи с тем что он не конкурентоспособен и он тупо длинный.

O1
```
bubbleSort:
	addiw	a2,a1,-2
	slli	a5,a2,32
	srli	a2,a5,30
	addi	a5,a0,4
	add	a2,a2,a5
	li	a7,1
	li	t1,0
	j	.L4
.L5:
	addi	a5,a5,4
	beq	a5,a2,.L10
.L6:
	lw	a4,0(a5)
	lw	a3,4(a5)
	ble	a4,a3,.L5
	sw	a3,0(a5)
	sw	a4,4(a5)
	mv	a6,a7
	j	.L5
.L10:
	beq	a6,zero,.L3
.L4:
	ble	a1,a7,.L3
	mv	a5,a0
	mv	a6,t1
	j	.L6
.L3:
	ret
	.size	bubbleSort, .-bubbleSort
	.section	.rodata.str1.8,"aMS",@progbits,1
	.align	3
.LC0:
	.string	"w"
	.align	3
.LC1:
	.string	"bubble_gcc.csv"
	.align	3
.LC3:
	.string	"%f\n"
	.text
	.align	1
	.globl	main
	.type	main, @function
```

O2
```
bubbleSort:
	li	a5,1
	ble	a1,a5,.L4
	addiw	a2,a1,-2
	slli	a5,a2,32
	srli	a2,a5,30
	addi	a5,a0,4
	add	a2,a2,a5
.L9:
	mv	a5,a0
	li	a1,0
.L7:
	lw	a4,0(a5)
	lw	a3,4(a5)
	ble	a4,a3,.L6
	sw	a3,0(a5)
	sw	a4,4(a5)
	li	a1,1
.L6:
	addi	a5,a5,4
	bne	a5,a2,.L7
	bne	a1,zero,.L9
.L4:
	ret
	.size	bubbleSort, .-bubbleSort
	.section	.rodata.str1.8,"aMS",@progbits,1
	.align	3
.LC0:
	.string	"w"
	.align	3
.LC1:
	.string	"bubble_gcc.csv"
	.align	3
.LC3:
	.string	"%f\n"
	.section	.text.startup,"ax",@progbits
	.align	1
	.globl	main
	.type	main, @function
```

Код при O2 оптимизации короче, также они сильно отличаются логикой проверок. Код при O2 оптимизации короче из-за постоянного использования условных переходов, тогда как O1 использует в циклах безусловные переходы.
Сравним непосредственно вложенные циклы:

O1
```
.L5:
	addi	a5,a5,4
	beq	a5,a2,.L10
.L6:
	lw	a4,0(a5)
	lw	a3,4(a5)
	ble	a4,a3,.L5
	sw	a3,0(a5)
	sw	a4,4(a5)
	mv	a6,a7
	j	.L5
.L10:   ;выход из функции сортировки
	beq	a6,zero,.L3 ;переход на выход
.L4:
	ble	a1,a7,.L3
	mv	a5,a0
	mv	a6,t1
	j	.L6
.L3:    ;выход
	ret
	.size	bubbleSort, .-bubbleSort
	.section	.rodata.str1.8,"aMS",@progbits,1
	.align	3
```

O2
```
.L9:
	mv	a5,a0
	li	a1,0
.L7:
	lw	a4,0(a5)
	lw	a3,4(a5)
	ble	a4,a3,.L6
	sw	a3,0(a5)
	sw	a4,4(a5)
	li	a1,1
.L6:
	addi	a5,a5,4
	bne	a5,a2,.L7
	bne	a1,zero,.L9
.L4:    ;выход
	ret
	.size	bubbleSort, .-bubbleSort
	.section	.rodata.str1.8,"aMS",@progbits,1
	.align	3
```

Как видно из кода при O2 оптимизации при каждом проходе цикла будет 2 либо 3 условные проверки. Тогда как в O1 будет либо 2 условные либо 2 условные и 1 безусловная либо 3 условные. 

Я не нашел время выполнения переходов в тактах, но если предположить что все варианты равновероятны (что с O2 можно за уши притянуть, а для O1 неверно, 3 условных перехода менее вероятны) и условный выполняется за 2 такта а безусловный за 1, то матожидание у обоих будет равно 5 = 1/2\*(2\*2 + 3\*2) = 1/3\*(2\*2 + (2\*2 + 1) + 3\*2). Но с у четом сказанного о вероятности, O1 может выполняться быстрее, что и происходит.

Исходя из asm кода для О3, логика оптимизации циклов у него такая же как и у O2, т.к. код просто тот же самый. При этом в чем разница вообще между ними я не увидел.

## LLVM

### Первый взгляд на ассемблер

Кода сильно больше чем у gcc, 299 против 242 у О0, 263 против 178 при О1, ииииии, барабанная дробь 779 и 778 строчек в O2 и O3 против пофиг скольки.

Честно говоря, анализ O2 и O3 провести нереально, просто из-за объемов кода. Предполагаю что оптимизация скорости достигаетс за счет уменьшения количества вызовов, но такой ценой...